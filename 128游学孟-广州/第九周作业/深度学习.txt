深度学习框架：
五个核心组件
1.张量(Tensor)
2.基于张量的各种操作(Operation)
3.计算图(Computation Graph)
4.自动微分(Automatic Differentiation)工具
5.BLAS,cuBLAS,cuDNN等拓展包

张量是所有深度学习框架中最核心的组件，
四阶张量表示一个包含多张图片的数据集，其中的四个维度分别是：图片在数据集中的编号，图片高度，
宽度，以及色彩数据。N,H,W,C

优势：
将各种各样的数据抽象成张量表示，然后再输入神经网络模型进行后续处理是一种非常必要且高效
的策略。

整个神经网络都可以简单视为为了达到谋种目的，针对输入张量进行的一系列操作过程。而所谓的学习
就是不断纠正神经网络的实际输出结果和预期结果之间误差的过程。

一系列操作包含的范围很宽，可以简单的矩阵乘法，也可以是卷积，池化和LSTM等稍复杂的预算。

计算图作为前后端之间的中间表示(Intermediate Representations)可以带来良好的交互性，
开发者可以将Tensor对象作为数据结构，函数/方法作为操作类型，将特定的操作类型应用于特定的数据
结构，从而定义出类似MATLAB的强大建模语言。

Tensor(张量)
构建图的预算过程输出的结果是一个Tensor，主要由三个属性构成：Name,Shape和Type。
*Name代表的是张量的名字，也是张量的唯一标识，
*shape代表张量当然维度
*Type表示张量的类型。

变量Variables维护图执行过程中的状态信息

Fetch:为了取回操作的输出内容，可以使用session独享的run()调用执行图时，传入一些tensor，这些
tensor会帮助取回结果。

Feed：使用一个tensor值临时替换一个操作的输出结果。可以提供feed数据作为run()调用
的参数。
Feed只在调用它的方法内有效，放大结束，feed就会消失，最常见的用例就是将某些特殊的
操作指定为"feed"操作，标记的方法是使用tf.placeholder()为这些操作创建占位符。

placeholder是一个数据初始化的容器，它与变量最大的不同与placeholder定义的是一个模板，这样
我们可以再session运行阶段，利用feed_dict的字典结构给placeholder填充具体内容，而
无需每次都提前定义好变量的值，大大提高了代码的利用率。

Tensorboard是tensorflow内置的一个可视化工具，它通过将tensorflow程序输出的日志
文件的信息可视化使得tensorflow程序的理解，调试和优化更简单高效。

Tensorboard的可视化依赖于tensorflow程序运行输出的日志文件，因而tensorboard和
tensorflow程序在不同进程中运行。

Pytorch-神经网络
torch.nn.Module提供了神经网络的基类，当实现神经网络时需要继承自此模块。并在初始化函数
中创建网路需要包含的层，并实现forward函数完成前向计算，网络的方向计算会自动求导机制处理。

SGD又称online的梯度下降，每次估计梯度的时候，只选用一个或几个batch训练样本？？？
这里的一步指的是迭代数还是批次批数

问题1：SGD中的每一步指的是批次批数还是迭代的代数
收敛指的是什么？是误差值波动稳定吗？还是收敛成一个数学模型。
什么是梯度动量？
什么梯度指数？
损失函数的反向传播指代的是什么？






























